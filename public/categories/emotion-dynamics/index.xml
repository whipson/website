<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Emotion Dynamics on Will Hipson</title>
    <link>/categories/emotion-dynamics/</link>
    <description>Recent content in Emotion Dynamics on Will Hipson</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2019</copyright>
    <lastBuildDate>Tue, 25 Jun 2019 00:00:00 +0000</lastBuildDate>
    
        <atom:link href="/categories/emotion-dynamics/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>A Model and Simulation of Emotion Dynamics</title>
      <link>/post/emotion-simulation1/emotion_sim/</link>
      <pubDate>Tue, 25 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/emotion-simulation1/emotion_sim/</guid>
      <description>


&lt;p&gt;Emotion dynamics is the study of how emotions change over time. Sometimes our feelings are quite stable, but other times capricious. Measuring and predicting these patterns for different people is somewhat of a Holy Grail for emotion researchers. In particular, some researchers are aspiring to discover mathematical laws that capture the complexity of our inner emotional experiences - much like physicists divining the laws that govern objects in the natural environment. These discoveries would revolutionize our understanding of our everyday feelings and when our emotions can go awry.&lt;/p&gt;
&lt;p&gt;This series of blog posts, which I kicked off earlier this month with a &lt;a href=&#34;https://willhipson.netlify.com/post/basketball_sim/basketball_sim/&#34;&gt;simulation of emotions during basketball games&lt;/a&gt;, is inspired by researchers like &lt;a href=&#34;https://ppw.kuleuven.be/okp/people/Peter_Kuppens/&#34;&gt;Peter Kuppens&lt;/a&gt; and &lt;a href=&#34;https://www.queensu.ca/psychology/people/faculty/tom-hollenstein&#34;&gt;Tom Hollenstein&lt;/a&gt; (to name a few) who have collected and analyzed reams of intensive self-reports on people’s feelings from one moment to the next. My approach is to reverse engineer these insights and generate models that &lt;em&gt;simulate&lt;/em&gt; emotions evolving over time - like this:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/post/emotion-simulation1/Emotion_Simulation_files/figure-html/unnamed-chunk-1-1.gif&#34; /&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;div id=&#34;affective-state-space&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Affective State Space&lt;/h2&gt;
&lt;p&gt;We start with the affective state space - the theoretical landscape on which our conscious feelings roam free. This space is represented as &lt;em&gt;two-dimensional&lt;/em&gt;, although we acknowledge that this fails to capture all aspects of conscious feeling. The first dimension, represented along the x-axis, is &lt;em&gt;valence&lt;/em&gt; and this refers to how unpleasant vs. pleasant we feel. The second dimension, represented along the y-axis, is &lt;em&gt;arousal&lt;/em&gt;. Somewhat less intuitive, arousal refers to how deactivated/sluggish/sleepy vs. activated/energized/awake we feel. At any time, our emotional state can be defined in terms of valence and arousal. So if you’re feeling stressed you would be low in valence and high in arousal. Let’s say you’re serene and calm, then you would be high in valence and low in arousal. Most of the time, we feel moderately high valence and moderate arousal (i.e., content), but if you’re the type of person who is chronically stressed, this would be different.&lt;/p&gt;
&lt;p&gt;This is all well and good when we think about how we’re feeling right now, but it’s also worth considering how our emotions are changing. On a regular day, our emotions undergo minor fluctuations - sometimes in response to minor hassles or victories, and sometimes for no discernible reason. In this small paragraph, I’ve laid out a number of parameters, all of which vary between different people:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Attractor&lt;/strong&gt;: Our typical emotional state. At any given moment, our feelings are pulled toward this state. Some people tend to be happier, whereas others are less happy.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Stability&lt;/strong&gt;: How emotionally stable one is. Some people are more emotionally stable than others. Even in the face of adversity, an emotionally stable person keeps their cool.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Dispersion&lt;/strong&gt;: The range of our emotional landscape. Some people experience intense highs and lows, whereas others persist somewhere in the middle.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We’ll keep all of this in mind for the simulation. We’ll start with a fairly simple simulation with 100 hypothetical people. We’ll need the following packages.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(psych)
library(tidyverse)
library(sn)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And then we’ll create a function that performs the simulation. Note that each person &lt;em&gt;i&lt;/em&gt; has their own attractor, recovery rate, stability, and dispersion. For now we’ll just model random fluctuations in emotions, a sort of Brownian motion. You can imagine our little &lt;strong&gt;simulatons&lt;/strong&gt; (fun name for the hypothetical people in the simulation) sitting around on an average day doing nothing in particular.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;simulate_affect &amp;lt;- function(n = 2, time = 250, negative_event_time = NULL) {
  dt &amp;lt;- data.frame(matrix(nrow = time, ncol = 1))
  colnames(dt) &amp;lt;- &amp;quot;time&amp;quot;
  dt$time &amp;lt;- 1:time
  
  valence &amp;lt;- data.frame(matrix(nrow = time, ncol = 0))
  arousal &amp;lt;- data.frame(matrix(nrow = time, ncol = 0))
  
  for(i in 1:n) {
    attractor_v &amp;lt;- rnorm(1, mean = 3.35, sd = .75)
    instability_v &amp;lt;- sample(3:12, 1, replace = TRUE, prob = c(.18, .22, .18, .15, .8, .6, .5, .4, .2, .1))
    dispersion_v &amp;lt;- abs(rsn(1, xi = .15, omega = .02, alpha = -6) * instability_v) #rsn simulates a skewed distribution.
    if(!is.null(negative_event_time)) {
      recovery_rate &amp;lt;- sample(1:50, 1, replace = TRUE) + negative_event_time
      negative_event &amp;lt;- (dt$time %in% negative_event_time:recovery_rate) * seq.int(50, 1, -1)
    }
    else {
      negative_event &amp;lt;- 0
    }
    valence[[i]] &amp;lt;- ksmooth(x = dt$time,
                            y = (negative_event * -.10) + arima.sim(list(order = c(1, 0, 0),
                                               ar = .50),
                                          n = time),
                            bandwidth = time/instability_v, kernel = &amp;quot;normal&amp;quot;)$y * dispersion_v + attractor_v 

#instability is modelled in the bandwidth term of ksmooth, such that higher instability results in higher bandwidth (greater fluctuation). 
#dispersion scales the white noise (arima) parameter, such that there are higher peaks and troughs at higher dispersion.
    
    attractor_a &amp;lt;- rnorm(1, mean = .50, sd = .75) + sqrt(instability_v) #arousal attractor is dependent on instability. This is because high instability is associated with higher arousal states.
    instability_a &amp;lt;- instability_v + sample(-1:1, 1, replace = TRUE)
    dispersion_a &amp;lt;- abs(rsn(1, xi = .15, omega = .02, alpha = -6) * instability_a)
    arousal[[i]] &amp;lt;- ksmooth(x = dt$time,
                            y = (negative_event * .075) + arima.sim(list(order = c(1, 0, 0),
                                               ar = .50),
                                          n = time),
                            bandwidth = time/instability_a, kernel = &amp;quot;normal&amp;quot;)$y * dispersion_a + attractor_a
  }
  
  valence[valence &amp;gt; 6] &amp;lt;- 6
  valence[valence &amp;lt; 0] &amp;lt;- 0
  arousal[arousal &amp;gt; 6] &amp;lt;- 6
  arousal[arousal &amp;lt; 0] &amp;lt;- 0
  
  colnames(valence) &amp;lt;- paste0(&amp;quot;valence_&amp;quot;, 1:n)
  colnames(arousal) &amp;lt;- paste0(&amp;quot;arousal_&amp;quot;, 1:n)
  
  dt &amp;lt;- cbind(dt, valence, arousal)
  
  return(dt)
}

set.seed(190625)

emotions &amp;lt;- simulate_affect(n = 100, time = 300)

emotions %&amp;gt;%
  select(valence_1, arousal_1) %&amp;gt;%
  head()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   valence_1 arousal_1
## 1  1.328024  5.380643
## 2  1.365657  5.385633
## 3  1.401849  5.390470
## 4  1.436284  5.395051
## 5  1.468765  5.399162
## 6  1.499062  5.402752&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So we see the first six rows for participant 1’s valence and arousal. But if we want to plot these across multiple simulatons, we need to wrangle the data into long form. We’ll also compute some measures of within-person deviation. The Root Mean Square Successive Difference (RMSSD) takes into account gradual shifts in the mean. Those who are more emotionally unstable will have a higher RMSSD. For two dimensions (valence and arousal) we’ll just compute the mean RMSSD.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;emotions_long &amp;lt;- emotions %&amp;gt;%
  gather(key, value, -time) %&amp;gt;%
  separate(key, into = c(&amp;quot;dimension&amp;quot;, &amp;quot;person&amp;quot;), sep = &amp;quot;_&amp;quot;) %&amp;gt;%
  spread(dimension, value) %&amp;gt;%
  group_by(person) %&amp;gt;%
  mutate(rmssd_v = rmssd(valence),
         rmssd_a = rmssd(arousal),
         rmssd_total = mean(rmssd_v + rmssd_a)) %&amp;gt;%
  ungroup()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s see what this looks like for valence and arousal individually.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;emotions_long %&amp;gt;%
  ggplot(aes(x = time, y = valence, group = person, color = rmssd_v)) +
  geom_line(size = .75, alpha = .75) +
  scale_color_gradient2(low = &amp;quot;black&amp;quot;, mid = &amp;quot;grey&amp;quot;, high = &amp;quot;red&amp;quot;, midpoint = median(emotions_long$rmssd_v)) +
  labs(x = &amp;quot;Time&amp;quot;,
       y = &amp;quot;Valence&amp;quot;,
       color = &amp;quot;Instability&amp;quot;,
       title = &amp;quot;Simulated Valence Scores over Time for 100 People&amp;quot;) +
  theme_minimal(base_size = 16)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/emotion-simulation1/Emotion_Simulation_files/figure-html/unnamed-chunk-5-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;emotions_long %&amp;gt;%
  ggplot(aes(x = time, y = arousal, group = person, color = rmssd_a)) +
  geom_line(size = .75, alpha = .75) +
  scale_color_gradient2(low = &amp;quot;black&amp;quot;, mid = &amp;quot;grey&amp;quot;, high = &amp;quot;red&amp;quot;, midpoint = median(emotions_long$rmssd_a)) +
  labs(x = &amp;quot;Time&amp;quot;,
       y = &amp;quot;Arousal&amp;quot;,
       color = &amp;quot;Instability&amp;quot;,
       title = &amp;quot;Simulated Arousal Scores over Time for 100 People&amp;quot;) +
  theme_minimal(base_size = 16)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/emotion-simulation1/Emotion_Simulation_files/figure-html/unnamed-chunk-5-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;We see that some lines are fairly flat and others fluctuate more widely. More importantly, most people are somewhere in the middle.&lt;/p&gt;
&lt;p&gt;We can get a sense of one simulated person’s affective state space as well. The goal here is to mimic the kinds of models shown in &lt;a href=&#34;https://www.ncbi.nlm.nih.gov/pubmed/20853980&#34;&gt;Kuppens, Oravecz, and Tuerlinckx (2010)&lt;/a&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;emotions_long %&amp;gt;%
  filter(person %in% sample(1:100, 6, replace = FALSE)) %&amp;gt;%
  ggplot(aes(x = valence, y = arousal, group = person)) +
  geom_path(size = .75) + 
  scale_x_continuous(limits = c(0, 6)) +
  scale_y_continuous(limits = c(0, 6)) +
  labs(x = &amp;quot;Valence&amp;quot;,
       y = &amp;quot;Arousal&amp;quot;,
       title = &amp;quot;Affective State Space for Six Randomly Simulated People&amp;quot;) +
  facet_wrap(~person) +
  theme_minimal(base_size = 18) +
  theme(plot.title = element_text(size = 18, hjust = .5))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/emotion-simulation1/Emotion_Simulation_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;animating-the-affective-state-space&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Animating the Affective State Space&lt;/h2&gt;
&lt;p&gt;To really appreciate what’s going on, we need to animate this over time. I’ll add some labels to the affective state space so that it’s easier to interpret what one might be feeling at that time. I’ll also add color to show which individuals are more unstable according to RMSSD.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(gganimate)

p &amp;lt;- emotions_long %&amp;gt;%
  ggplot(aes(x = valence, y = arousal, color = rmssd_total)) +
  annotate(&amp;quot;text&amp;quot;, x = c(1.5, 4.5, 1.5, 4.5), y = c(1.5, 1.5, 4.5, 4.5), label = c(&amp;quot;Gloomy&amp;quot;, &amp;quot;Calm&amp;quot;, &amp;quot;Anxious&amp;quot;, &amp;quot;Happy&amp;quot;),
           size = 10, alpha = .50) + 
  annotate(&amp;quot;rect&amp;quot;, xmin = 0, xmax = 3, ymin = 0, ymax = 3, alpha = 0.25, color = &amp;quot;black&amp;quot;, fill = &amp;quot;white&amp;quot;) +
  annotate(&amp;quot;rect&amp;quot;, xmin = 3, xmax = 6, ymin = 0, ymax = 3, alpha = 0.25, color = &amp;quot;black&amp;quot;, fill = &amp;quot;white&amp;quot;) +
  annotate(&amp;quot;rect&amp;quot;, xmin = 0, xmax = 3, ymin = 3, ymax = 6, alpha = 0.25, color = &amp;quot;black&amp;quot;, fill = &amp;quot;white&amp;quot;) +
  annotate(&amp;quot;rect&amp;quot;, xmin = 3, xmax = 6, ymin = 3, ymax = 6, alpha = 0.25, color = &amp;quot;black&amp;quot;, fill = &amp;quot;white&amp;quot;) +
  geom_point(size = 3.5) +
  scale_color_gradient2(low = &amp;quot;black&amp;quot;, mid = &amp;quot;grey&amp;quot;, high = &amp;quot;red&amp;quot;, midpoint = median(emotions_long$rmssd_total)) +
  scale_x_continuous(limits = c(0, 6)) +
  scale_y_continuous(limits = c(0, 6)) +
  labs(x = &amp;quot;Valence&amp;quot;,
       y = &amp;quot;Arousal&amp;quot;,
       color = &amp;quot;Instability&amp;quot;,
       title = &amp;#39;Time: {round(frame_time)}&amp;#39;) +
  transition_time(time) +
  theme_minimal(base_size = 18)

ani_p &amp;lt;- animate(p, nframes = 320, end_pause = 20, fps = 16, width = 550, height = 500)

ani_p&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/emotion-simulation1/Emotion_Simulation_files/figure-html/unnamed-chunk-7-1.gif&#34; /&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;theres-a-storm-coming&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;There’s a Storm Coming…&lt;/h2&gt;
&lt;p&gt;Our simulation does a pretty good job at emulating the natural ebb and flow of emotions, but we know that emotions can be far more volatile. Let’s subject our simulation to a negative event. Perhaps all 100 &lt;strong&gt;simulatons&lt;/strong&gt; co-authored a paper that just got rejected. In the function &lt;em&gt;simulate_affect&lt;/em&gt;, there’s an optional argument &lt;em&gt;negative_event_time&lt;/em&gt; that causes a negative event to occur at the specified time. For this, we need to consider one more emotion dynamics parameter:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Recovery rate&lt;/strong&gt;: How quickly one recovers from an emotional event. If something bad happens, how long does it take to return to the attractor. You can see how I’ve modelled this parameter in the function above.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;So we’ll run the simulation with a negative event arising at &lt;em&gt;t&lt;/em&gt; = 150. The negative event will cause a downward spike in valence and an upward spike in arousal.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;emotions_event &amp;lt;- simulate_affect(n = 100, time = 300, negative_event_time = 150)

emotions_event_long &amp;lt;- emotions_event %&amp;gt;%
  gather(key, value, -time) %&amp;gt;%
  separate(key, into = c(&amp;quot;dimension&amp;quot;, &amp;quot;person&amp;quot;), sep = &amp;quot;_&amp;quot;) %&amp;gt;%
  spread(dimension, value) %&amp;gt;%
  group_by(person) %&amp;gt;%
  mutate(rmssd_v = rmssd(valence),
         rmssd_a = rmssd(arousal),
         rmssd_total = mean(rmssd_v + rmssd_a)) %&amp;gt;%
  ungroup()

emotions_event_long %&amp;gt;%
  ggplot(aes(x = time, y = valence, group = person, color = rmssd_v)) +
  geom_line(size = .75, alpha = .75) +
  scale_color_gradient2(low = &amp;quot;black&amp;quot;, mid = &amp;quot;grey&amp;quot;, high = &amp;quot;red&amp;quot;, midpoint = median(emotions_event_long$rmssd_v)) +
  labs(x = &amp;quot;Time&amp;quot;,
       y = &amp;quot;Valence&amp;quot;,
       color = &amp;quot;Instability&amp;quot;,
       title = &amp;quot;Simulated Valence Scores over Time for 100 People&amp;quot;) +
  theme_minimal(base_size = 16)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/emotion-simulation1/Emotion_Simulation_files/figure-html/unnamed-chunk-8-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;emotions_event_long %&amp;gt;%
  ggplot(aes(x = time, y = arousal, group = person, color = rmssd_a)) +
  geom_line(size = .75, alpha = .75) +
  scale_color_gradient2(low = &amp;quot;black&amp;quot;, mid = &amp;quot;grey&amp;quot;, high = &amp;quot;red&amp;quot;, midpoint = median(emotions_event_long$rmssd_a)) +
  labs(x = &amp;quot;Time&amp;quot;,
       y = &amp;quot;Arousal&amp;quot;,
       color = &amp;quot;Instability&amp;quot;,
       title = &amp;quot;Simulated Arousal Scores over Time for 100 People&amp;quot;) +
  theme_minimal(base_size = 16)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/emotion-simulation1/Emotion_Simulation_files/figure-html/unnamed-chunk-8-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;It’s pretty clear that something bad happened. Of course, some of our &lt;strong&gt;simulatons&lt;/strong&gt; are unflappable, but most experienced a drop in valence and spike in arousal that we might identify as anxiety. Again, let’s visualize this evolving over time. Pay close attention to when the timer hits 150.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;p2 &amp;lt;- emotions_event_long %&amp;gt;%
  ggplot(aes(x = valence, y = arousal, color = rmssd_total)) +
  annotate(&amp;quot;text&amp;quot;, x = c(1.5, 4.5, 1.5, 4.5), y = c(1.5, 1.5, 4.5, 4.5), label = c(&amp;quot;Gloomy&amp;quot;, &amp;quot;Calm&amp;quot;, &amp;quot;Anxious&amp;quot;, &amp;quot;Happy&amp;quot;),
           size = 10, alpha = .50) + 
  annotate(&amp;quot;rect&amp;quot;, xmin = 0, xmax = 3, ymin = 0, ymax = 3, alpha = 0.25, color = &amp;quot;black&amp;quot;, fill = &amp;quot;white&amp;quot;) +
  annotate(&amp;quot;rect&amp;quot;, xmin = 3, xmax = 6, ymin = 0, ymax = 3, alpha = 0.25, color = &amp;quot;black&amp;quot;, fill = &amp;quot;white&amp;quot;) +
  annotate(&amp;quot;rect&amp;quot;, xmin = 0, xmax = 3, ymin = 3, ymax = 6, alpha = 0.25, color = &amp;quot;black&amp;quot;, fill = &amp;quot;white&amp;quot;) +
  annotate(&amp;quot;rect&amp;quot;, xmin = 3, xmax = 6, ymin = 3, ymax = 6, alpha = 0.25, color = &amp;quot;black&amp;quot;, fill = &amp;quot;white&amp;quot;) +
  geom_point(size = 3.5) +
  scale_color_gradient2(low = &amp;quot;black&amp;quot;, mid = &amp;quot;grey&amp;quot;, high = &amp;quot;red&amp;quot;, midpoint = median(emotions_event_long$rmssd_total)) +
  scale_x_continuous(limits = c(0, 6)) +
  scale_y_continuous(limits = c(0, 6)) +
  labs(x = &amp;quot;Valence&amp;quot;,
       y = &amp;quot;Arousal&amp;quot;,
       color = &amp;quot;Instability&amp;quot;,
       title = &amp;#39;Time: {round(frame_time)}&amp;#39;) +
  transition_time(time) +
  theme_minimal(base_size = 18)

ani_p2 &amp;lt;- animate(p2, nframes = 320, end_pause = 20, fps = 16, width = 550, height = 500)

ani_p2&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/emotion-simulation1/Emotion_Simulation_files/figure-html/unnamed-chunk-9-1.gif&#34; /&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;p&gt;The overall picture is that some are more emotionally resilient than others. As of now, all the &lt;strong&gt;simulatons&lt;/strong&gt; return to their baseline attractor, but we would realistically expect some to stay stressed or gloomy following bad news. In the coming months I’ll be looking into how to incorporate emotion regulation into the simulation. For example, maybe some of the &lt;strong&gt;simulatons&lt;/strong&gt; use better coping strategies than others? I’m also interested in incorporating &lt;em&gt;appraisal&lt;/em&gt; mechanisms that allow for different reactions depending on the type of emotional stimulus.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;References&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://www.ncbi.nlm.nih.gov/pubmed/20853980&#34;&gt;Kuppens, P., Oravecz, Z., &amp;amp; Tuerlinckx, F. (2010). Feelings change: Accounting for individual differences in the temporal dynamics of affect. &lt;em&gt;Journal of Personality and Social Psychology, 99&lt;/em&gt;, 1042-1060&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
      
            <category>R</category>
      
      
            <category>R</category>
      
            <category>Emotion Dynamics</category>
      
    </item>
    
    <item>
      <title>Simulating Emotions during a Basketball Game - Just a Feeling in the Crowd</title>
      <link>/post/basketball_sim/basketball_sim/</link>
      <pubDate>Wed, 05 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/basketball_sim/basketball_sim/</guid>
      <description>


&lt;p&gt;Sporting events host witness to a wide range of human emotion. The emotional ups and downs are especially clear among invested fans. Fans experience the joy and excitement of a triumphant comeback, or the anxiety and disappointment of a loss. It is particularly interesting to see how emotions differ from two opposing fan groups watching the same match.&lt;/p&gt;
&lt;p&gt;I decided to perform some simulations on how a crowd of fans would react during a basketball game. Why basketball? Two reasons: First is the frequency of scoring (more baskets = more &lt;em&gt;reactive&lt;/em&gt; simulation), and second is that the NBA finals are in swing at time of writing.&lt;/p&gt;
&lt;p&gt;Below I’ve described the parameters of the simulation in detail and provided reproducible code for all examples, but here’s the quick and dirty. I’m simulating fans’ happiness and nerves (valence and arousal). Happiness reflects baskets scored (up for team basket and down for enemy basket) and overall team performance. Nerves reflects baskets scored, time remaining in game, and the difference between score (higher for closer game). There are other parameters involved that are described in more detail below.&lt;/p&gt;
&lt;p&gt;Let’s run the simulation! I’m simulating a short game that’s about 16 minutes long, but the simulation is sped up. There are 25 fans per team with each dot representing a fan. Blue dots root for the blue team and red dots for red. In this game, blue starts ahead, but red makes a rallying comeback.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/post/basketball_sim/Basketball_Simulation_files/figure-html/unnamed-chunk-1-1.gif&#34; /&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;p&gt;What are we seeing here? As the game progresses, fans move into different emotional states. I’ve used the terms &lt;em&gt;content&lt;/em&gt;, &lt;em&gt;disappointed&lt;/em&gt;, &lt;em&gt;nervous&lt;/em&gt;, and &lt;em&gt;excited&lt;/em&gt; as helpful placeholders, but we should think of these in terms of varying along dimensions of &lt;em&gt;valence&lt;/em&gt; (e.g., happiness) and &lt;em&gt;arousal&lt;/em&gt; (e.g., nerves, excitedness). For example, when their team is doing well, fans are happier, but they’re only excited when the score is close. For each basket, there’s a brief spike in arousal and happiness. As the game draws closer to an end, fans get more excited/anxious, especially if the score is close.&lt;/p&gt;
&lt;p&gt;So how would this play out if one team decimated the other? Let’s give the red team a slight edge over blue:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/post/basketball_sim/Basketball_Simulation_files/figure-html/unnamed-chunk-2-1.gif&#34; /&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;p&gt;Notice how ‘excited’ becomes ‘content’ and ‘nervous’ turns to ‘disappointment’ because the difference becomes insurmountable for the blue team. We can plug in any numbers for this function to produce different results. However, the algorithm is highly sensitive to small changes in scoring chance because this is calculated for every &lt;em&gt;second&lt;/em&gt; of the game.&lt;/p&gt;
&lt;div id=&#34;going-behind-the-simulation&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Going Behind the Simulation&lt;/h2&gt;
&lt;p&gt;Skip this if you have no interest in the psychology of emotions. What I’m striving to simulate are the laws of emotion dynamics (Kuppens &amp;amp; Verduyn, 2017). Emotions change from moment to moment, but there’s also some stability from one moment to the next. Apart from when a basket is scored, most fans cluster around a particular state (this is called an &lt;em&gt;attractor state&lt;/em&gt;). Any change is attributable to random fluctuations (e.g., one fan spills some of their beer, maybe another fan sees an amusing picture of a cat on their phone). When a basket &lt;em&gt;is&lt;/em&gt; scored, this causes a temporary fluctuation away from the attractor state, after which people resort back to their attractor. More gradual situational factors result in small changes in attractors too. This is why arousal tends to increase with closer games and when the game is approaching the end.&lt;/p&gt;
&lt;div id=&#34;detailed-aspects-of-simulation-and-code&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Detailed Aspects of Simulation and Code&lt;/h3&gt;
&lt;p&gt;There are two parts to this simulation. Part 1 simulates a basketball game for a specified duration of time (&lt;em&gt;n_seconds&lt;/em&gt;) and specified probabilities of scoring. The simulation is also designed with a small post game period - sort of like a cool down after the game. During the post game, fans’ arousal returns to baseline.&lt;/p&gt;
&lt;p&gt;The second and more complicated part of the simulation is the emotional part. Each fan has a score on valence and arousal at each second. These can be further broken down into fixed effects and random effects. The fixed effect for valence is described as follows:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[Valence = 3 + \beta_{1overall.difference}(.20) + \beta_{2recent.score(1.5 + \frac{current.time}{total.time})} - \beta_{3recent.enemy.score}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The fixed effect for arousal looks like this:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[Arousal = 3 + \beta_{1 (\frac{current.time}{total.time})(.75)(post.game)} + \beta_{2(1 - \sqrt{|difference|})} + \beta_{3|recent.basket|}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The exact values for these coefficients are somewhat arbitrary. They resulted from a lot of trial and error to identify which best simulated emotion dynamics.&lt;/p&gt;
&lt;p&gt;Each fan’s valence and arousal is calculated using the above equations + variability. The variability is added by applying random variation to the first constant in the above equations and white noise with a simulated ARIMA model. On top of this, I used a kernel regression smoother to smooth out each fan’s trajectory. To simulate delayed reaction time to baskets, I added some &lt;em&gt;lags&lt;/em&gt; at random intervals - otherwise the simulated fans appear to react quicker than the score board. Here’s what all of this looks like for one fan’s valence over time:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)

game_long %&amp;gt;%
  filter(fan == 1,
         team == &amp;quot;team1&amp;quot;) %&amp;gt;%
  ggplot(aes(x = second, y = valence)) +
  geom_line(color = &amp;quot;red&amp;quot;, size = 1) +
  theme_minimal(base_size = 16) +
  labs(title = &amp;quot;Fan One&amp;#39;s Valence over Time&amp;quot;,
       x = &amp;quot;Time&amp;quot;,
       y = &amp;quot;Valence&amp;quot;) +
  theme(legend.position = &amp;quot;none&amp;quot;,
        axis.title.x = element_text(size = 18),
        axis.title.y = element_text(size = 18),
        plot.title = element_text(size = 18, hjust = .5))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/basketball_sim/Basketball_Simulation_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;We can see this across all fans as well:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;game_long %&amp;gt;%
  ggplot(aes(x = instance, color = team)) +
  geom_line(aes(y = valence), alpha = .65) +
  labs(title = &amp;quot;Valence over Time&amp;quot;,
       x = &amp;quot;Time&amp;quot;,
       y = &amp;quot;Valence&amp;quot;) +
  theme_minimal() +
  theme(legend.position = &amp;quot;none&amp;quot;,
        axis.title.x = element_text(size = 18),
        axis.title.y = element_text(size = 18),
        plot.title = element_text(size = 18, hjust = .5))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/basketball_sim/Basketball_Simulation_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;And for arousal…&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;game_long %&amp;gt;%
  ggplot(aes(x = instance, color = team)) +
  geom_line(aes(y = arousal), alpha = .65) +
  labs(title = &amp;quot;Arousal over Time&amp;quot;,
       x = &amp;quot;Time&amp;quot;,
       y = &amp;quot;Arousal&amp;quot;) +
  theme_minimal() +
  theme(legend.position = &amp;quot;none&amp;quot;,
        axis.title.x = element_text(size = 18),
        axis.title.y = element_text(size = 18),
        plot.title = element_text(size = 18, hjust = .5))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/basketball_sim/Basketball_Simulation_files/figure-html/unnamed-chunk-5-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;For those interested, here’s the full code for the simulation and first animation. Have fun with it! I’m also looking for ways to improve it. Ironically, I don’t watch a ton of sports, so if you think I’m open to input on how to make it more realistic!&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
library(forecast)
library(gganimate)
library(extrafont)

game_simulation &amp;lt;- function(n_seconds = 1000, n_fans = 25, team1_prob = 0.012, team2_prob = 0.012) {
  
  score_board &amp;lt;- data.frame(matrix(nrow = n_seconds, ncol = 5))
  colnames(score_board) &amp;lt;- c(&amp;quot;second&amp;quot;, &amp;quot;team1_score&amp;quot;, &amp;quot;team2_score&amp;quot;, &amp;quot;difference&amp;quot;, &amp;quot;end_game&amp;quot;)
  score_board$second &amp;lt;- c(1:n_seconds)
  
  score_board$team1_score &amp;lt;- cumsum(sample(c(0, 1, 1.5), n_seconds, replace = TRUE, prob = c(1 - team1_prob, team1_prob * .90, team1_prob * .10)))
  
  score_board$team2_score &amp;lt;- cumsum(sample(c(0, 1, 1.5), n_seconds, replace = TRUE, prob = c(1 - team2_prob, team2_prob * .90, team2_prob * .10)))
  
  score_board$difference &amp;lt;- score_board$team1_score - score_board$team2_score
  
  score_board$end_game = 1
  
  total_time &amp;lt;- n_seconds + n_seconds * .05
  
  end_time &amp;lt;- data.frame(max(score_board$second + 1):(total_time))
  colnames(end_time) &amp;lt;- &amp;quot;second&amp;quot;
  end_state &amp;lt;- score_board[nrow(score_board), 2:5]
  post_game &amp;lt;- data.frame(matrix(nrow = n_seconds * .05, ncol = 0),
                          &amp;quot;team1_score&amp;quot; = end_state$team1_score,
                          &amp;quot;team2_score&amp;quot; = end_state$team2_score,
                          &amp;quot;difference&amp;quot; = end_state$difference,
                          &amp;quot;end_game&amp;quot; = 0)
  
  post_game &amp;lt;- cbind(end_time, post_game)
  
  score_board &amp;lt;- rbind(score_board, post_game)
  
  valence &amp;lt;- function(time, overall_difference, recent_team_score, recent_enemy_score) (
    (overall_difference * .20) + (recent_team_score * (1.5 + time/length(time))) - (recent_enemy_score)
  )
  
  arousal &amp;lt;- function(time, difference, recent_score, end_game) (
    ((time/n_seconds) * .75 * end_game) + (1 - sqrt(abs(difference))) + abs(recent_score * 1.5)
  )
  
  team1_valence &amp;lt;- data.frame(matrix(nrow = total_time, ncol = 0))
  team1_arousal &amp;lt;- data.frame(matrix(nrow = total_time, ncol = 0))
  team2_valence &amp;lt;- data.frame(matrix(nrow = total_time, ncol = 0))
  team2_arousal &amp;lt;- data.frame(matrix(nrow = total_time, ncol = 0))
  
  for(i in 1:n_fans) {

    team1_valence[[i]] &amp;lt;- ksmooth(x = score_board$second,
                                  y = rnorm(n = 1, mean = 3, sd = .25) + (arima.sim(list(order = c(1, 0, 1), ma = -.1, ar = c(.9)), n = total_time) * .25) + valence(time = score_board$second,
                                  overall_difference = score_board$difference,
                                  recent_team_score = lag(score_board$team1_score, n = sample(c(1:5), 1), default = 0) - lag(score_board$team1_score, n = sample(c(6:8), 1), default = 0),
                                  recent_enemy_score = lag(score_board$team2_score, n = sample(c(1:5), 1), default = 0) - lag(score_board$team2_score, n = sample(c(6:8), 1), default = 0)),
                                  bandwidth = total_time/100, kernel = &amp;quot;normal&amp;quot;)$y
    
  }
  
  colnames(team1_valence) &amp;lt;- paste0(&amp;quot;team1_&amp;quot;, &amp;quot;valence_&amp;quot;, 1:n_fans)
  team1_valence[team1_valence &amp;gt; 6] &amp;lt;- 6
  team1_valence[team1_valence &amp;lt; 0] &amp;lt;- 0
  
  for(i in 1:n_fans) {
    team1_arousal[[i]] &amp;lt;- ksmooth(x = score_board$second,
                                  y = rnorm(n = 1, mean = 3, sd = .25) + (arima.sim(list(order = c(1, 0, 1), ma = -.1, ar = c(.9)), n = total_time) * .25) + arousal(time = score_board$second,
                                  difference = score_board$difference,
                                  recent_score = lag(score_board$difference, n = sample(c(1:3), 1), default = 0) - lag(score_board$difference, n = sample(c(4:6), 1), default = 0),
                                  end_game = score_board$end_game),
                                  bandwidth = total_time/100, kernel = &amp;quot;normal&amp;quot;)$y
  }
  
  colnames(team1_arousal) &amp;lt;- paste0(&amp;quot;team1_&amp;quot;, &amp;quot;arousal_&amp;quot;, 1:n_fans)
  
  team1_arousal[team1_arousal &amp;gt; 6] &amp;lt;- 6
  team1_arousal[team1_arousal &amp;lt; 0] &amp;lt;- 0
   
  for(i in 1:n_fans) {
    team2_valence[[i]] &amp;lt;- ksmooth(x = score_board$second,
                                  y = rnorm(n = 1, mean = 3, sd = .25) + (arima.sim(list(order = c(1, 0, 1), ma = -.1, ar = c(.9)), n = total_time) * .25) + valence(time = score_board$second,
                                  overall_difference = -score_board$difference,
                                  recent_team_score = lag(score_board$team2_score, n = sample(c(1:5), 1), default = 0) - lag(score_board$team2_score, n = sample(c(6:8), 1), default = 0),
                                  recent_enemy_score = lag(score_board$team1_score, n = sample(c(1:5), 1), default = 0) - lag(score_board$team1_score, n = sample(c(6:8), 1), default = 0)),
                                  bandwidth = total_time/100, kernel = &amp;quot;normal&amp;quot;)$y
  }
  
  colnames(team2_valence) &amp;lt;- paste0(&amp;quot;team2_&amp;quot;, &amp;quot;valence_&amp;quot;, 1:n_fans)
  
  team2_valence[team2_valence &amp;gt; 6] &amp;lt;- 6
  team2_valence[team2_valence &amp;lt; 0] &amp;lt;- 0
  
  for (i in 1:n_fans) {
    team2_arousal[[i]] &amp;lt;- ksmooth(x = score_board$second,
                                  y = rnorm(n = 1, mean = 3, sd = .25) + (arima.sim(list(order = c(1, 0, 1), ma = -.1, ar = c(.9)), n = total_time) * .25) + arousal(time = score_board$second,
                                  difference = score_board$difference,
                                  recent_score = lag(score_board$difference, n = sample(c(1:3), 1), default = 0) - lag(score_board$difference, n = sample(c(4:6), 1), default = 0),
                                  end_game = score_board$end_game),
                                  bandwidth = total_time/100, kernel = &amp;quot;normal&amp;quot;)$y
  }
  
  colnames(team2_arousal) &amp;lt;- paste0(&amp;quot;team2_&amp;quot;, &amp;quot;arousal_&amp;quot;, 1:n_fans)
  
  team2_arousal[team2_arousal &amp;gt; 6] &amp;lt;- 6
  team2_arousal[team2_arousal &amp;lt; 0] &amp;lt;- 0
  
  game_affect &amp;lt;- cbind(score_board, team1_valence, team1_arousal, team2_valence, team2_arousal)
  
  return(game_affect)
}

set.seed(060519)

game &amp;lt;- game_simulation(n_seconds = 1000, n_fans = 25)

game_long &amp;lt;- game %&amp;gt;%
  mutate(instance = row_number(),
         team1_score = team1_score * 2,
         team2_score = team2_score * 2) %&amp;gt;%
  select(instance, everything()) %&amp;gt;%
  select(-end_game) %&amp;gt;%
  gather(key = &amp;quot;team&amp;quot;, value = &amp;quot;score&amp;quot;, c(team1_valence_1:length(game))) %&amp;gt;%
  separate(col = team, into = c(&amp;quot;team&amp;quot;, &amp;quot;dimension&amp;quot;, &amp;quot;fan&amp;quot;), sep = &amp;quot;_&amp;quot;) %&amp;gt;%
  spread(dimension, score)
  
p &amp;lt;- game_long %&amp;gt;%
  ggplot() +
  annotate(&amp;quot;rect&amp;quot;, xmin = 0, xmax = 3, ymin = 0, ymax = 3, alpha = 0.5, fill = &amp;quot;lightblue&amp;quot;) +
  annotate(&amp;quot;rect&amp;quot;, xmin = 3, xmax = 6, ymin = 0, ymax = 3, alpha = 0.5, fill = &amp;quot;lightgreen&amp;quot;) +
  annotate(&amp;quot;rect&amp;quot;, xmin = 0, xmax = 3, ymin = 3, ymax = 6, alpha = 0.2, fill = &amp;quot;red&amp;quot;) +
  annotate(&amp;quot;rect&amp;quot;, xmin = 3, xmax = 6, ymin = 3, ymax = 6, alpha = 0.2, fill = &amp;quot;yellow&amp;quot;) +
  annotate(&amp;quot;text&amp;quot;, x = c(1.5, 4.5, 1.5, 4.5), y = c(1.5, 1.5, 4.5, 4.5), label = c(&amp;quot;Disappointed&amp;quot;, &amp;quot;Content&amp;quot;, &amp;quot;Nervous&amp;quot;, &amp;quot;Excited&amp;quot;),
           size = 10, alpha = .50, family = &amp;quot;Verdana&amp;quot;) +
  geom_text(aes(x = 1.5, y = 5.5, label = paste(&amp;quot;Red:&amp;quot;, team1_score)), size = 8, color = &amp;quot;red&amp;quot;, family = &amp;quot;Verdana&amp;quot;) +
  geom_text(aes(x = 4.5, y = 5.5, label = paste(&amp;quot;Blue:&amp;quot;, team2_score)), size = 8, color = &amp;quot;blue&amp;quot;, family = &amp;quot;Verdana&amp;quot;) +
  geom_point(aes(x = valence, y = arousal, color = team), alpha = .70, size = 4) +
  scale_x_continuous(limits = c(0, 6)) +
  scale_y_continuous(limits = c(0, 6)) +
  scale_color_manual(values = c(&amp;quot;red&amp;quot;, &amp;quot;blue&amp;quot;)) +
  labs(title = &amp;#39;Time: {round((max(game_long$second) - frame_time)/60, 2)}&amp;#39;,
       x = &amp;quot;Happiness&amp;quot;,
       y = &amp;quot;Nerves&amp;quot;) +
  theme_minimal(base_size = 16) +
  transition_time(second) +
  theme(legend.position = &amp;quot;none&amp;quot;,
        axis.title.x = element_text(size = 18),
        axis.title.y = element_text(size = 18),
        plot.title = element_text(size = 18, hjust = .5),
        text = element_text(family = &amp;quot;Verdana&amp;quot;))

game1 &amp;lt;- animate(p, nframes = 1062, width = 500, height = 500, fps = 14, end_pause = 12)

game1&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;References&lt;/h3&gt;
&lt;p&gt;Kuppens P, Verduyn P. (2017). Emotion dynamics. &lt;em&gt;Current Opinion in Psychology. 17&lt;/em&gt;, 22–26. doi: 10.1016/j.copsyc.2017.06.004.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
      
            <category>R</category>
      
      
            <category>R</category>
      
            <category>Emotion Dynamics</category>
      
    </item>
    
    <item>
      <title>Network Analysis of Emotions</title>
      <link>/post/emotion-network/emotion-network/</link>
      <pubDate>Mon, 18 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/emotion-network/emotion-network/</guid>
      <description>
&lt;script src=&#34;/rmarkdown-libs/htmlwidgets/htmlwidgets.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;/rmarkdown-libs/d3/d3.min.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;/rmarkdown-libs/forceNetwork-binding/forceNetwork.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;In this month’s post, I set out to create a visual network of emotions. Emotion Dynamics tells us that different emotions are highly interconnected, such that one emotion morphs into another and so on. I’ll be using a large dataset from an original study published in PLOS ONE by &lt;a href=&#34;https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0145450&#34;&gt;Trampe, Quoidbach, and Taquet (2015)&lt;/a&gt;. Thanks to &lt;a href=&#34;https://toolbox.google.com/datasetsearch&#34;&gt;Google Dataset Search&lt;/a&gt;, I was able to locate this data. The data is collected from 11,000 participants who completed daily questionnaires on the emotions they felt at a given moment. The original paper is fascinating and I highly encourage checking it out - not to mention that the author’s analysis is the inspiration for this post. The raw data can be freely accessed from the author’s OSF page (link in online article) - props to them for publishing the data!&lt;/p&gt;
&lt;p&gt;What is a network? In a sentence, a network is a complex set of interrelations between variables. Some terminology: &lt;em&gt;nodes&lt;/em&gt; are the variables (in this case, emotions), and &lt;em&gt;edges&lt;/em&gt; are the relationships between the variables. Networks can be &lt;em&gt;directed&lt;/em&gt;, which means that variables are linked in a sequence (e.g, from emotion A to emotion B), or &lt;em&gt;undirected&lt;/em&gt;, which just shows the relationships. Trampe et al. (2015) created an undirected network in their paper, but the data also allows for a directed network - and this is what I’m going to make for this post.&lt;/p&gt;
&lt;p&gt;First, I’ll read in the data and fix up a few spelling errors from the original dataset.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)

emotion_raw &amp;lt;- read_csv(&amp;quot;https://osf.io/e7uab/download&amp;quot;) %&amp;gt;%
  rename(Offense = Ofense,
         Embarrassment = Embarassment)

emotion_raw&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 69,544 x 21
##       id Hours   Day Pride  Love  Hope Gratitude   Joy Satisfaction   Awe
##    &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;        &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
##  1     1     1     3     0     0     0         0     0            0     0
##  2     1    14     1     0     0     0         0     0            0     0
##  3     1    14     2     0     0     0         0     0            0     0
##  4     1    14     4     0     0     0         0     0            0     0
##  5     1    15     3     0     0     0         0     0            0     0
##  6     1    15     3     0     0     0         0     0            0     0
##  7     1    19     1     0     0     0         0     0            0     0
##  8     8     8     5     0     0     0         0     1            0     0
##  9     8     9     2     0     0     0         0     1            0     0
## 10     8    10     7     0     0     0         0     0            0     0
## # ... with 69,534 more rows, and 11 more variables: Amusement &amp;lt;dbl&amp;gt;,
## #   Alertness &amp;lt;dbl&amp;gt;, Anxiety &amp;lt;dbl&amp;gt;, Disdain &amp;lt;dbl&amp;gt;, Offense &amp;lt;dbl&amp;gt;,
## #   Guilt &amp;lt;dbl&amp;gt;, Disgust &amp;lt;dbl&amp;gt;, Fear &amp;lt;dbl&amp;gt;, Embarrassment &amp;lt;dbl&amp;gt;,
## #   Sadness &amp;lt;dbl&amp;gt;, Anger &amp;lt;dbl&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The data is formatted as a sparse matrix (lots of zeros). We have participant id, Day, and Hour that the emotion was reported. To make this data network compatible, I need to wrangle it into a dataframe of &lt;em&gt;edges&lt;/em&gt; - that is a &lt;em&gt;from&lt;/em&gt; column and a &lt;em&gt;to&lt;/em&gt; column. This will become more apparent shortly.&lt;/p&gt;
&lt;p&gt;I can use the function &lt;em&gt;gather&lt;/em&gt; to turn the data into long format. By filtering for values of 1, I remove all the zeros from the sparse matrix and I’m left with a column that includes the emotion that was experienced at the time of reporting.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;emotion_long &amp;lt;- emotion_raw %&amp;gt;%
  gather(emotion_type, value, Pride:Anger) %&amp;gt;%
  arrange(id, Day) %&amp;gt;%
  filter(value == 1) %&amp;gt;%
  select(-value)

emotion_long&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 187,426 x 4
##       id Hours   Day emotion_type 
##    &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;        
##  1     1    19     1 Offense      
##  2     1    19     1 Sadness      
##  3     1    14     2 Disgust      
##  4     1    15     3 Alertness    
##  5     1    15     3 Anxiety      
##  6     1    15     3 Embarrassment
##  7     1    15     3 Sadness      
##  8     1    14     4 Alertness    
##  9     1    14     4 Embarrassment
## 10     8     9     2 Joy          
## # ... with 187,416 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Still, there are no edges here - no link between one emotion and the next. Because the data is arranged so that each subsequent row is the next emotion, I can create a new variable, second_emotion, that is the &lt;em&gt;lead&lt;/em&gt; of the emotion in that row. Then, I make sure to remove the last row from each participant id (otherwise there would be a relationship between Participant #1’s last emotion and Participant #2’s first emotion).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;emotion_edges &amp;lt;- emotion_long %&amp;gt;%
  mutate(second_emotion = lead(emotion_type)) %&amp;gt;%
  rename(first_emotion = emotion_type) %&amp;gt;%
  select(id, Day, Hours, first_emotion, second_emotion) %&amp;gt;%
  group_by(id) %&amp;gt;%
  slice(-length(id))

emotion_edges&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 175,480 x 5
## # Groups:   id [11,332]
##       id   Day Hours first_emotion second_emotion
##    &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;         &amp;lt;chr&amp;gt;         
##  1     1     1    19 Offense       Sadness       
##  2     1     1    19 Sadness       Disgust       
##  3     1     2    14 Disgust       Alertness     
##  4     1     3    15 Alertness     Anxiety       
##  5     1     3    15 Anxiety       Embarrassment 
##  6     1     3    15 Embarrassment Sadness       
##  7     1     3    15 Sadness       Alertness     
##  8     1     4    14 Alertness     Embarrassment 
##  9     8     2     9 Joy           Alertness     
## 10     8     2     9 Alertness     Alertness     
## # ... with 175,470 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Notice how first and second emotion form a sort of chain - Offense to Sadness, Sadness to Disgust, Disgust to Alertness, etc.&lt;/p&gt;
&lt;p&gt;We’re ignoring the fact that people are experiencing multiple emotions at once and in those instances we don’t know which emotion was experienced first.&lt;/p&gt;
&lt;p&gt;Now that we have our edges, we need to create an object containing the nodes. This is pretty simple, but I’ll add some information indicating the valence and frequency (n) of each emotion, which will help with the visualizations that follow.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;emotion_nodes &amp;lt;- emotion_long %&amp;gt;%
  count(emotion_type) %&amp;gt;%
  rowid_to_column(&amp;quot;id&amp;quot;) %&amp;gt;%
  rename(label = emotion_type) %&amp;gt;%
  mutate(valence = ifelse(label %in% c(&amp;quot;Awe&amp;quot;, &amp;quot;Amusement&amp;quot;, &amp;quot;Joy&amp;quot;, &amp;quot;Alertness&amp;quot;,
                                              &amp;quot;Hope&amp;quot;, &amp;quot;Love&amp;quot;, &amp;quot;Gratitude&amp;quot;, &amp;quot;Pride&amp;quot;,
                                              &amp;quot;Satisfaction&amp;quot;), &amp;quot;positive&amp;quot;, &amp;quot;negative&amp;quot;))

emotion_nodes&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 18 x 4
##       id label             n valence 
##    &amp;lt;int&amp;gt; &amp;lt;chr&amp;gt;         &amp;lt;int&amp;gt; &amp;lt;chr&amp;gt;   
##  1     1 Alertness     17932 positive
##  2     2 Amusement     11136 positive
##  3     3 Anger          6394 negative
##  4     4 Anxiety       19115 negative
##  5     5 Awe            3830 positive
##  6     6 Disdain         682 negative
##  7     7 Disgust        7412 negative
##  8     8 Embarrassment  3000 negative
##  9     9 Fear           3457 negative
## 10    10 Gratitude      7379 positive
## 11    11 Guilt          3500 negative
## 12    12 Hope          16665 positive
## 13    13 Joy           23465 positive
## 14    14 Love          18625 positive
## 15    15 Offense        3160 negative
## 16    16 Pride          9214 positive
## 17    17 Sadness       13460 negative
## 18    18 Satisfaction  19000 positive&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We now have an object containing our nodes and an object containing our edges. Now it’s a matter of weighting (counting) the relationships between the emotions.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;emotion_network &amp;lt;- emotion_edges %&amp;gt;%
  group_by(first_emotion, second_emotion) %&amp;gt;%
  summarize(weight = n()) %&amp;gt;%
  ungroup() %&amp;gt;%
  select(first_emotion, second_emotion, weight)

emotion_network&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 315 x 3
##    first_emotion second_emotion weight
##    &amp;lt;chr&amp;gt;         &amp;lt;chr&amp;gt;           &amp;lt;int&amp;gt;
##  1 Alertness     Alertness        6191
##  2 Alertness     Amusement          97
##  3 Alertness     Anger             214
##  4 Alertness     Anxiety          4784
##  5 Alertness     Awe                14
##  6 Alertness     Disdain            82
##  7 Alertness     Disgust           544
##  8 Alertness     Embarrassment     208
##  9 Alertness     Fear              109
## 10 Alertness     Gratitude          70
## # ... with 305 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;A few more modifications are needed to make it ready for visualization. I’m trimming some of the really high values using &lt;em&gt;ifelse&lt;/em&gt;, just so that they don’t overwhelm the plotting screen.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;edges &amp;lt;- emotion_network %&amp;gt;%
  left_join(emotion_nodes, by = c(&amp;quot;first_emotion&amp;quot; = &amp;quot;label&amp;quot;)) %&amp;gt;%
  rename(from = id)

edges &amp;lt;- edges %&amp;gt;%
  left_join(emotion_nodes, by = c(&amp;quot;second_emotion&amp;quot; = &amp;quot;label&amp;quot;)) %&amp;gt;%
  rename(to = id) %&amp;gt;%
  select(from, to, weight) %&amp;gt;%
  mutate(weight = ifelse(weight &amp;gt; 4500, 4500, weight))

edges&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 315 x 3
##     from    to weight
##    &amp;lt;int&amp;gt; &amp;lt;int&amp;gt;  &amp;lt;dbl&amp;gt;
##  1     1     1   4500
##  2     1     2     97
##  3     1     3    214
##  4     1     4   4500
##  5     1     5     14
##  6     1     6     82
##  7     1     7    544
##  8     1     8    208
##  9     1     9    109
## 10     1    10     70
## # ... with 305 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We need the &lt;em&gt;tidygraph&lt;/em&gt; and &lt;em&gt;ggraph&lt;/em&gt; packages for the visualization. I’ll note that there are a number of packages for visualizing networks, but &lt;em&gt;ggraph&lt;/em&gt; seems to be preferred because it is compatible with ggplot terminology. The function &lt;em&gt;tbl_graph&lt;/em&gt; will take the nodes and edges and make them ggraph ready.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidygraph)
library(ggraph)

network &amp;lt;- tbl_graph(emotion_nodes, edges, directed = TRUE)

set.seed(190318)

ggraph(network, layout = &amp;quot;graphopt&amp;quot;) +
  geom_edge_link(aes(width = weight, color = scale(weight), alpha = weight), check_overlap = TRUE) +
  scale_edge_color_gradient2(low = &amp;quot;darkgrey&amp;quot;, mid = &amp;quot;#00BFFF&amp;quot;, midpoint = 1.5, high = &amp;quot;dodgerblue2&amp;quot;) +
  scale_edge_width(range = c(.2, 1.75)) +
  geom_node_label(aes(label = label, fill = valence), size = 4) +
  scale_fill_manual(values = c(&amp;quot;#FF6A6A&amp;quot;, &amp;quot;#43CD80&amp;quot;)) +
  theme_graph() +
  theme(legend.position = &amp;quot;none&amp;quot;, plot.background = element_rect(fill = &amp;quot;black&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/emotion-network/Emotion_Network_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Stronger relationships show up as thicker lines. Positive emotions seem to be more pronounced and interconnected, which is what was found in the original article. Unfortunately, we don’t get a good sense of temporality (adding directional arrows creates more of a mess than anything). An interactive plot might be more informative, so let’s try that using &lt;em&gt;networkD3&lt;/em&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(networkD3)

nodes_d3 &amp;lt;- emotion_nodes %&amp;gt;%
  mutate(id = id - 1,
         n = (scale(n) + 3)^3)

edges_d3 &amp;lt;- edges %&amp;gt;%
  mutate(from = from - 1, to = to - 1,
         weight = ifelse(weight &amp;lt; 600, 0, log(weight)))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It’s VERY important to transform the values to base 0, which is why I’m using mutate -1. networkD3 won’t work on base 1 values.&lt;/p&gt;
&lt;p&gt;Again, I’ve made a few adjustments for visualization purposes. Namely, I’m removing relationships that occur less than 600 times and scaling the values somewhat arbitrarily. Of course, this is exploratory analysis, but caution should be taken when interpreting these results. The function &lt;em&gt;forceNetwork&lt;/em&gt; takes the nodes and edges specified above and turns them into something beautiful.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;forceNetwork(Links = edges_d3, Nodes = nodes_d3, Source = &amp;quot;from&amp;quot;, Nodesize = &amp;quot;n&amp;quot;,
             Target = &amp;quot;to&amp;quot;, NodeID = &amp;quot;label&amp;quot;, Group = &amp;quot;valence&amp;quot;, Value = &amp;quot;weight&amp;quot;, fontFamily = &amp;quot;sans-serif&amp;quot;,
             colourScale = JS(&amp;#39;d3.scaleOrdinal().domain([&amp;quot;negative&amp;quot;, &amp;quot;positive&amp;quot;]).range([&amp;quot;#FF6A6A&amp;quot;, &amp;quot;#43CD80&amp;quot;])&amp;#39;),
             opacity = 1, fontSize = 24, linkDistance = 300, linkColour = c(&amp;quot;#8DB6CD&amp;quot;),
             arrows = TRUE, zoom = TRUE, bounded = TRUE, legend = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Links is a tbl_df. Converting to a plain data frame.&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Nodes is a tbl_df. Converting to a plain data frame.&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;htmlwidget-1&#34; style=&#34;width:672px;height:480px;&#34; class=&#34;forceNetwork html-widget&#34;&gt;&lt;/div&gt;
&lt;script type=&#34;application/json&#34; data-for=&#34;htmlwidget-1&#34;&gt;{&#34;x&#34;:{&#34;links&#34;:{&#34;source&#34;:[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17],&#34;target&#34;:[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,0,1,2,3,5,6,7,8,9,10,11,12,13,14,15,16,17,0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,0,1,2,3,4,5,6,7,9,10,11,12,13,14,15,16,17,0,1,2,3,4,6,7,8,9,10,11,12,13,14,15,16,17,0,1,2,3,4,6,7,9,10,11,12,13,14,15,16,17,0,1,2,3,4,6,7,8,9,10,11,12,13,14,15,16,17,0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,0,1,2,3,6,7,8,9,10,11,12,13,14,15,16,17,0,1,2,3,4,6,7,8,9,10,11,12,13,14,15,16,17,0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17],&#34;value&#34;:[8.41183267575841,0,0,8.41183267575841,0,0,0,0,0,0,0,0,0,6.55393340402581,0,6.78219205600679,6.52795791762255,0,8.33591109419694,7.97108575350561,0,7.26262860097424,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,7.13169851046691,0,0,0,0,0,0,0,0,0,0,6.80903930604298,0,6.60934924316738,0,0,0,0,0,8.41183267575841,0,0,7.38770923908104,0,6.77308037565554,0,7.16317239084664,0,0,6.68959926917897,7.24921505711439,6.44571981938558,7.46336304552002,0,6.4425401664682,7.38523092306657,0,0,6.89365635460264,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,7.46508273639955,0,6.99209642741589,0,0,0,0,0,0,0,7.78030308790837,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,7.11151211649616,0,0,0,0,0,0,0,6.49978704065585,6.61606518513282,0,0,0,0,0,0,0,7.06561336359772,0,0,0,0,0,0,0,0,7.93092537248339,0,0,8.15679704667565,0,0,0,0,0,0,0,0,0,0,7.03790596344718,0,0,0,6.54821910276237,0,0,0,0,0,0,0,6.4377516497364,0,0,6.58063913728495,0,0,0,0,0,8.02092771898158,0,8.41183267575841,8.3513747067213,0,0,0,0,6.63463335786169,7.13009851012558,7.40488757561612,0,6.82219739062049,0,0,0,0,0,0,0,0,8.41183267575841,0,0,0,0,8.41183267575841,0,0,0,6.69456205852109,0,0,0,0,0,0,0,8.41183267575841,7.99361999482774,8.41183267575841,0,0,0,0,0,0,0,0,6.94119005506837,0,0,0,6.50876913697168,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,7.27309259599952,6.55393340402581,8.17723488551019,0,7.92334821193015,0,0,0,0,8.10379671298179,0,0,0,0,0,0,0,0,0,0,6.96129604591017,0,6.60123011872888,8.33471162182092,0,7.87853419614036,8.12058871174027,0,7.23128700432762,7.57250298502038,0,0,0,0,0,0,0,0,0,0,0,0,8.41183267575841],&#34;colour&#34;:[&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;,&#34;#8DB6CD&#34;]},&#34;nodes&#34;:{&#34;name&#34;:[&#34;Alertness&#34;,&#34;Amusement&#34;,&#34;Anger&#34;,&#34;Anxiety&#34;,&#34;Awe&#34;,&#34;Disdain&#34;,&#34;Disgust&#34;,&#34;Embarrassment&#34;,&#34;Fear&#34;,&#34;Gratitude&#34;,&#34;Guilt&#34;,&#34;Hope&#34;,&#34;Joy&#34;,&#34;Love&#34;,&#34;Offense&#34;,&#34;Pride&#34;,&#34;Sadness&#34;,&#34;Satisfaction&#34;],&#34;group&#34;:[&#34;positive&#34;,&#34;positive&#34;,&#34;negative&#34;,&#34;negative&#34;,&#34;positive&#34;,&#34;negative&#34;,&#34;negative&#34;,&#34;negative&#34;,&#34;negative&#34;,&#34;positive&#34;,&#34;negative&#34;,&#34;positive&#34;,&#34;positive&#34;,&#34;positive&#34;,&#34;negative&#34;,&#34;positive&#34;,&#34;negative&#34;,&#34;positive&#34;],&#34;nodesize&#34;:[66.4777260049541,29.823109822341,14.4971585620182,74.9545346567671,8.99863483398379,4.41089086229159,17.1859473592041,7.57540966372343,8.33882236853888,17.0939636079722,8.41318408245376,58.1352372636087,112.27983133578,71.3610761571251,7.83713818129178,22.7248729842467,40.2101604728943,74.1005872923404]},&#34;options&#34;:{&#34;NodeID&#34;:&#34;label&#34;,&#34;Group&#34;:&#34;valence&#34;,&#34;colourScale&#34;:&#34;d3.scaleOrdinal().domain([\&#34;negative\&#34;, \&#34;positive\&#34;]).range([\&#34;#FF6A6A\&#34;, \&#34;#43CD80\&#34;])&#34;,&#34;fontSize&#34;:24,&#34;fontFamily&#34;:&#34;sans-serif&#34;,&#34;clickTextSize&#34;:60,&#34;linkDistance&#34;:300,&#34;linkWidth&#34;:&#34;function(d) { return Math.sqrt(d.value); }&#34;,&#34;charge&#34;:-30,&#34;opacity&#34;:1,&#34;zoom&#34;:true,&#34;legend&#34;:true,&#34;arrows&#34;:true,&#34;nodesize&#34;:true,&#34;radiusCalculation&#34;:&#34; Math.sqrt(d.nodesize)+6&#34;,&#34;bounded&#34;:true,&#34;opacityNoHover&#34;:0,&#34;clickAction&#34;:null}},&#34;evals&#34;:[],&#34;jsHooks&#34;:[]}&lt;/script&gt;
&lt;p&gt;Hovering over the nodes shows the emotion label and its relationships with other emotions. The arrows indicate directionality in time. It’s a good enough graph, although I would like for the labels to show up at all times. I still have lots to learn about network analysis.&lt;/p&gt;
&lt;p&gt;As a final note, I’ll mention that I neglected to adjust for the nested structure of the data - emotions nested within hours, days, and participants. This is crucial when conducting formal statistical tests, but should also be accounted for in visualizations.&lt;/p&gt;
&lt;div id=&#34;references-resources&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;References &amp;amp; Resources&lt;/h3&gt;
&lt;p&gt;This &lt;a href=&#34;https://www.jessesadler.com/post/network-analysis-with-r/&#34;&gt;blog post&lt;/a&gt; by Jesse Sadler really helped in the initial stages of my learning on network analysis.&lt;/p&gt;
&lt;p&gt;Trampe, D., Quoidbach, J., Taquet, M. (2015). Emotions in everyday life. &lt;em&gt;PLOS ONE&lt;/em&gt;. &lt;a href=&#34;https://doi.org/10.1371/journal.pone.0145450&#34; class=&#34;uri&#34;&gt;https://doi.org/10.1371/journal.pone.0145450&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
      
            <category>R</category>
      
            <category>Emotion Dynamics</category>
      
      
            <category>R</category>
      
            <category>Emotion Dynamics</category>
      
    </item>
    
    <item>
      <title>The Face of (Dis)Agreement - Intraclass Correlations</title>
      <link>/post/emotion-expression-icc/emotion-expression/</link>
      <pubDate>Mon, 04 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/emotion-expression-icc/emotion-expression/</guid>
      <description>
&lt;script src=&#34;/rmarkdown-libs/kePrint/kePrint.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;I was recently introduced to &lt;a href=&#34;https://toolbox.google.com/datasetsearch&#34;&gt;Google Dataset Search&lt;/a&gt;, an extension that searches for open access datasets. There I stumbled upon this dataset on childrens’ and adult’s ratings of facial expressions. The data comes from a published article by &lt;a href=&#34;https://www.tandfonline.com/doi/full/10.1080/17405629.2017.1287073&#34;&gt;Vesker et al. (2018)&lt;/a&gt;. Briefly, this study involved having adults and 9-year-old children rate a series of 48 faces on two dimensions of emotion, valence (positive vs. negative) and arousal (activated vs. deactivated) (see my previous &lt;a href=&#34;https://willhipson.netlify.com/post/circumplex/circumplex/&#34;&gt;post&lt;/a&gt; for more info on valence and arousal). The authors made some interesting observations about differences in childrens’ and adult’s ratings of these facial expressions.&lt;/p&gt;
&lt;p&gt;However, absent from the writeup was a discussion about how reliable these ratings are. We might wonder about the extent to which people agree on the valence or arousal of a face and whether this varies between children and adults. Here, I tackle the issue of intraclass correlation (ICC) using the dataset published by Vesker et al. (2018). The data itself is openly accessible &lt;a href=&#34;https://zenodo.org/record/293008#.XFXlr1xKhPZ&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;First, I’ll load up the &lt;em&gt;tidyverse&lt;/em&gt; and &lt;em&gt;readxl&lt;/em&gt; packages, which will help with the data cleaning.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(readxl)
library(tidyverse)

options(digits = 3, scipen = -2)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Upon downloading the data, we’re immediately presented with an issue: it’s an xlsx document (Excel) containing multiple sheets, with each sheet representing a “condition” (Child vs. Adult) and (Valence vs. Arousal). On Stack Overflow, I found a useful function for reading in multiple sheets (&lt;a href=&#34;https://stackoverflow.com/questions/12945687/read-all-worksheets-in-an-excel-workbook-into-an-r-list-with-data-frames&#34;&gt;see here for original post&lt;/a&gt;).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;read_excel_allsheets &amp;lt;- function(filename, tibble = TRUE) {
  sheets &amp;lt;- readxl::excel_sheets(filename)
  x &amp;lt;- lapply(sheets, function(x) readxl::read_excel(filename, sheet = x))
  if(!tibble) x &amp;lt;- lapply(x, as.data.frame)
  names(x) &amp;lt;- sheets
  x
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, I’ll read in the data and extract each sheet. I’m using VA to refer to valence and AR for arousal.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;faces &amp;lt;- read_excel_allsheets(&amp;quot;C:/Users/wille/Downloads/adults and 9yo all AR and VAL face ratings zenodo.xlsx&amp;quot;)

VA_adult_raw &amp;lt;- faces$`VAL adult faces`
VA_child_raw &amp;lt;- faces$`Val 9yo faces`
AR_adult_raw &amp;lt;- faces$`AR adult faces`
AR_child_raw &amp;lt;- faces$`AR 9yo faces`&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s get a look at one of these datasets.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;head(VA_adult_raw[, 1:20]) #Limiting preview to n = 20&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 20
##   ..1       ..2   ..3   ..4   ..5   ..6   ..7   ..8   ..9  ..10  ..11  ..12
##   &amp;lt;chr&amp;gt;   &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
## 1 dl sa ~     4     4     3     4     2     3     4     3     3     5     3
## 2 dl sa ~     4     4     3     3     2     3     3     3     3     4     4
## 3 lp sa ~     2     3     4     3     3     3     2     3     3     3     2
## 4 lp sa ~     4     3     2     3     3     3     4     2     2     4     2
## 5 ma sa ~     1     1     1     2     1     2     1     1     2     3     2
## 6 md sa ~     2     1     1     2     2     3     1     1     2     3     2
## # ... with 8 more variables: ..13 &amp;lt;dbl&amp;gt;, ..14 &amp;lt;dbl&amp;gt;, ..15 &amp;lt;dbl&amp;gt;,
## #   ..16 &amp;lt;dbl&amp;gt;, ..17 &amp;lt;dbl&amp;gt;, ..18 &amp;lt;dbl&amp;gt;, ..19 &amp;lt;dbl&amp;gt;, ..20 &amp;lt;dbl&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It’s not immediately apparent what is being displayed here because the columns aren’t labeled. The article tells us that participants rated 48 faces, so based on the dimensions we can assume that each row is a face and each column is a participant who rated that face. Admittedly, it’s a less intuitive way of representing the data, but its actually ideal for computing ICCs.&lt;/p&gt;
&lt;p&gt;Still, there’s a lot of data cleaning and wrangling to be done here. First, we have some rows and columns that aren’t relevant, so we’ll get rid of those. Of note, &lt;em&gt;dplyr&lt;/em&gt;’s lesser known &lt;em&gt;slice&lt;/em&gt; function is helpful for identifying which rows we want to keep.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;VA_adult &amp;lt;- VA_adult_raw %&amp;gt;%
  slice(1:48) %&amp;gt;%
  select(-1, -mean, -SD, -`M mean`, -`F mean`, -`dist from 4`, -`0`, -aa, -Valence) %&amp;gt;%
  mutate(face = row_number()) %&amp;gt;%
  select(face, everything())&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, to make the columns more intuitive, we’ll label them properly.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;colnames(VA_adult)[2:161] &amp;lt;- paste(&amp;quot;rater&amp;quot;, 1:160)&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;plotting-the-scores&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Plotting the Scores&lt;/h2&gt;
&lt;p&gt;We may want to plot the data to get a sense of the variability around raters’ labeling of valence across the 48 faces. Our data is currently in wide form, but we need to set it up such that all of the ratings are in one column. This is where &lt;em&gt;reshape2&lt;/em&gt; comes into action.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(reshape2)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The function &lt;em&gt;melt&lt;/em&gt; will take our wide dataset and make it long. We supply it with an &lt;em&gt;id.vars&lt;/em&gt; which tells it which of our original columns we want to stay as a column. Then it takes all of the other columns and condenses them into one variable.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;VA_adult_melt &amp;lt;- VA_adult %&amp;gt;%
  melt(id.vars = &amp;quot;face&amp;quot;, value.name = &amp;quot;valence&amp;quot;, variable.name = &amp;quot;rater&amp;quot;)

head(VA_adult_melt)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   face   rater valence
## 1    1 rater 1       4
## 2    2 rater 1       4
## 3    3 rater 1       2
## 4    4 rater 1       4
## 5    5 rater 1       1
## 6    6 rater 1       2&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now we’ll turn this into a line graph with each line representing an individual rater’s valence ratings for each of the 48 faces. It will be crowded, but that’s OK. We just want to see if the lines cluster around each other or not.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;VA_adult_melt %&amp;gt;%
  ggplot(aes(face, valence, group = rater, color = rater)) +
  geom_line(size = .8, alpha = .5) +
  scale_x_discrete(limits = 1:48) +
  geom_vline(xintercept = 24.5, size = 1.5, color = &amp;quot;red&amp;quot;) +
  labs(x = &amp;quot;Face&amp;quot;, y = &amp;quot;Valence (higher = more positive)&amp;quot;,
       title = &amp;quot;Adult Valence Ratings for 48 Faces&amp;quot;,
       subtitle = &amp;quot;Red line indicates where faces become positive&amp;quot;) +
  theme_bw() +
  theme(legend.position = &amp;quot;none&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/emotion-expression-icc/Face-Recognition_files/figure-html/unnamed-chunk-9-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;There’s a clear division between the positive and negative faces. It seems that there’s strong agreement among adults as to what constitutes a positive or negative face.&lt;/p&gt;
&lt;p&gt;What if we looked at the distributions of the ratings for each face?&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;VA_adult_melt %&amp;gt;%
  group_by(face) %&amp;gt;%
  summarize(mean = mean(valence),
            sd = sd(valence)) %&amp;gt;%
  ungroup() %&amp;gt;%
  ggplot(aes(face, mean)) +
  geom_errorbar(aes(ymin = mean - 1.96*(sd/sqrt(ncol(VA_adult))),
                    ymax = mean + 1.96*(sd/sqrt(ncol(VA_adult))))) +
  geom_point(size = 2) +
  scale_x_discrete(limits = 1:48) +
  geom_vline(xintercept = 24.5, color = &amp;quot;red&amp;quot;) +
  labs(x = &amp;quot;Face&amp;quot;, y = &amp;quot;Valence (higher = more positive)&amp;quot;,
       title = &amp;quot;Adult - Average Valence Ratings for 48 Faces&amp;quot;,
       subtitle = &amp;quot;Red line indicates where faces become positive; error bars = 95% CI&amp;quot;) +
  theme_bw()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/emotion-expression-icc/Face-Recognition_files/figure-html/unnamed-chunk-10-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;It tells the same story, but it’s a more polished figure. Notice how the error bars for the 95% confidence interval around the mean are quite small.&lt;/p&gt;
&lt;div id=&#34;cleaning-the-remaining-datasets&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Cleaning the Remaining Datasets&lt;/h3&gt;
&lt;p&gt;First, we’ll look at the dataset for 9-year-olds’ ratings of valence. Note that there are a few modifications to the script due to idiosyncracies with the original datasets.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;VA_child &amp;lt;- VA_child_raw %&amp;gt;%
  slice(2:49) %&amp;gt;%
  select(-1, -`average child ratings`, -33, -code,
         -`pic name`, -emotion, -`Child M`, -`Child F`, -sex, -Valence) %&amp;gt;%
  mutate(face = row_number()) %&amp;gt;%
  select(face, everything())

colnames(VA_child)[2:31] &amp;lt;- paste(&amp;quot;rater&amp;quot;, 1:30)

VA_child &amp;lt;- tbl_df(lapply(VA_child, function(x){ #Need to use a function to convert to numeric
  as.numeric(as.character(x)) 
}))

VA_child_melt &amp;lt;- VA_child %&amp;gt;%
  melt(id.vars = &amp;quot;face&amp;quot;, value.name = &amp;quot;valence&amp;quot;, variable.name = &amp;quot;rater&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;VA_child_melt %&amp;gt;%
  ggplot(aes(face, valence, group = rater, color = rater)) +
  geom_line(size = .8, alpha = .5) +
  scale_x_discrete(limits = 1:48) +
  geom_vline(xintercept = 24.5, size = 1.5, color = &amp;quot;red&amp;quot;) +
  labs(x = &amp;quot;Face&amp;quot;, y = &amp;quot;Valence (higher = more positive)&amp;quot;,
       title = &amp;quot;Child Valence Ratings for 48 Faces&amp;quot;,
       subtitle = &amp;quot;Red line indicates where faces become positive&amp;quot;) +
  theme_bw() +
  theme(legend.position = &amp;quot;none&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/emotion-expression-icc/Face-Recognition_files/figure-html/unnamed-chunk-12-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;VA_child_melt %&amp;gt;%
  group_by(face) %&amp;gt;%
  summarize(mean = mean(valence, na.rm = TRUE),
            sd = sd(valence, na.rm = TRUE)) %&amp;gt;%
  ungroup() %&amp;gt;%
  ggplot(aes(face, mean)) +
  geom_errorbar(aes(ymin = mean - 1.96*(sd/sqrt(ncol(VA_child))),
                    ymax = mean + 1.96*(sd/sqrt(ncol(VA_child))))) +
  geom_point(size = 2) +
  scale_x_discrete(limits = 1:48) +
  geom_vline(xintercept = 24.5, color = &amp;quot;red&amp;quot;) +
  labs(x = &amp;quot;Face&amp;quot;, y = &amp;quot;Valence (higher = more positive)&amp;quot;,
       title = &amp;quot;Child - Average Valence Ratings for 48 Faces&amp;quot;,
       subtitle = &amp;quot;Red line indicates where faces become positive; error bars = 95% CI&amp;quot;) +
  theme_bw()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/emotion-expression-icc/Face-Recognition_files/figure-html/unnamed-chunk-13-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The results are similar to those from the adults. We can’t trust the wider confidence intervals to tell us about reliability though, because there are far fewer child raters than adult raters.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;repeating-the-procedure-for-ratings-of-arousal&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Repeating the Procedure for Ratings of Arousal&lt;/h3&gt;
&lt;p&gt;Finally, we repeat the analysis for measures of arousal, starting with adults then with children.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;AR_adult &amp;lt;- AR_adult_raw %&amp;gt;%
  slice(1:48) %&amp;gt;%
  select(-1, -43, -SD, -`M mean`, -`F mean`, -mean, -`0`, -Valence) %&amp;gt;%
  mutate(face = row_number()) %&amp;gt;%
  select(face, everything())

colnames(AR_adult)[2:42] &amp;lt;- paste(&amp;quot;rater&amp;quot;, 1:41)

AR_adult_melt &amp;lt;- AR_adult %&amp;gt;%
  melt(id.vars = &amp;quot;face&amp;quot;, value.name = &amp;quot;arousal&amp;quot;, variable.name = &amp;quot;rater&amp;quot;)

AR_adult_melt %&amp;gt;%
  ggplot(aes(face, arousal, group = rater, color = rater)) +
  geom_line(size = .8, alpha = .5) +
  scale_x_discrete(limits = 1:48) +
  geom_vline(xintercept = 24.5, size = 1.5, color = &amp;quot;red&amp;quot;) +
  labs(x = &amp;quot;Face&amp;quot;, y = &amp;quot;Arousal (higher = more activated)&amp;quot;,
       title = &amp;quot;Adult Arousal Ratings for 48 Faces&amp;quot;,
       subtitle = &amp;quot;Red line indicates where faces become positive&amp;quot;) +
  theme_bw() +
  theme(legend.position = &amp;quot;none&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/emotion-expression-icc/Face-Recognition_files/figure-html/unnamed-chunk-14-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;There seems to be much less consensus for ratings of arousal. We do notice that there is no differentiation between positive and negative faces - this is good because the theory suggests that arousal is independent of valence. Someone can be positively aroused (e.g., excited) or negatively aroused (e.g., stressed). However, if there was high consensus we would still see the lines converging. Instead, they’re all over the place.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;AR_adult_melt %&amp;gt;%
  group_by(face) %&amp;gt;%
  summarize(mean = mean(arousal),
            sd = sd(arousal)) %&amp;gt;%
  ungroup() %&amp;gt;%
  ggplot(aes(face, mean)) +
  geom_errorbar(aes(ymin = mean - 1.96*(sd/sqrt(ncol(AR_adult))),
                    ymax = mean + 1.96*(sd/sqrt(ncol(AR_adult))))) +
  geom_point(size = 2) +
  scale_x_discrete(limits = 1:48) +
  geom_vline(xintercept = 24.5, color = &amp;quot;red&amp;quot;) +
  labs(x = &amp;quot;Face&amp;quot;, y = &amp;quot;Arousal (higher = more activated)&amp;quot;,
       title = &amp;quot;Adult - Average Arousal Ratings for 48 Faces&amp;quot;,
       subtitle = &amp;quot;Red line indicates where faces become positive; error bars = 95% CI&amp;quot;) +
  theme_bw()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/emotion-expression-icc/Face-Recognition_files/figure-html/unnamed-chunk-15-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Confidence intervals are much wider too, but again, we have a smaller sample size so that adds some uncertainty. Still, it seems like adults have difficulty agreeing on ratings of arousal compared to ratings of valence. Let’s go back to 9-year-olds.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;AR_child &amp;lt;- AR_child_raw %&amp;gt;%
  slice(2:49) %&amp;gt;%
  select(-`photo ID`, -child, -`adult ratings PELL`, -`Photo ID`,
         -30, -image, -emotion, -`m child`, -`f child`, -Valence) %&amp;gt;%
  mutate(face = row_number()) %&amp;gt;%
  select(face, everything())

colnames(AR_child)[2:31] &amp;lt;- paste(&amp;quot;rater&amp;quot;, 1:30)

AR_child &amp;lt;- tbl_df(lapply(AR_child, function(x){ #Need to use a function to convert to numeric
  as.numeric(as.character(x)) #Note: There is one missing value from original dataset
}))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning in FUN(X[[i]], ...): NAs introduced by coercion&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;AR_child_melt &amp;lt;- AR_child %&amp;gt;%
  melt(id.vars = &amp;quot;face&amp;quot;, value.name = &amp;quot;arousal&amp;quot;, variable.name = &amp;quot;rater&amp;quot;)

AR_child_melt %&amp;gt;%
  ggplot(aes(face, arousal, group = rater, color = rater)) +
  geom_line(size = .8, alpha = .5) +
  scale_x_discrete(limits = 1:48) +
  geom_vline(xintercept = 24.5, size = 1.5, color = &amp;quot;red&amp;quot;) +
  labs(x = &amp;quot;Face&amp;quot;, y = &amp;quot;Arousal (higher = more activated)&amp;quot;,
       title = &amp;quot;Child Arousal Ratings for 48 Faces&amp;quot;,
       subtitle = &amp;quot;Red line indicates where faces become positive&amp;quot;) +
  theme_bw() +
  theme(legend.position = &amp;quot;none&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: Removed 48 rows containing missing values (geom_path).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/emotion-expression-icc/Face-Recognition_files/figure-html/unnamed-chunk-16-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;AR_child_melt %&amp;gt;%
  group_by(face) %&amp;gt;%
  summarize(mean = mean(arousal, na.rm = TRUE),
            sd = sd(arousal, na.rm = TRUE)) %&amp;gt;%
  ungroup() %&amp;gt;%
  ggplot(aes(face, mean)) +
  geom_errorbar(aes(ymin = mean - 1.96*(sd/sqrt(ncol(AR_child))),
                    ymax = mean + 1.96*(sd/sqrt(ncol(AR_child))))) +
  geom_point(size = 2) +
  scale_x_discrete(limits = 1:48) +
  geom_vline(xintercept = 24.5, color = &amp;quot;red&amp;quot;) +
  labs(x = &amp;quot;Face&amp;quot;, y = &amp;quot;Arousal (higher = more activated)&amp;quot;,
       title = &amp;quot;Child - Average Arousal Ratings for 48 Faces&amp;quot;,
       subtitle = &amp;quot;Red line indicates where faces become positive; error bars = 95% CI&amp;quot;) +
  theme_bw()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/emotion-expression-icc/Face-Recognition_files/figure-html/unnamed-chunk-17-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Results look similar for children. I won’t spend much time discussing mean differences in valence and arousal between children and adults - the original article expands on this. However, I am interested in the variability in ratings of arousal vs. valence.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;quantifying-interrater-agreement&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Quantifying Interrater Agreement&lt;/h2&gt;
&lt;p&gt;So far, we’ve created a series of plots showing the variability in childrens’ and adult’s ratings of emotional facial expressions. We get a sense that both children and adults reliably label faces as positive or negative, but they struggle to agree on arousal. Although this is apparent from the plots, we may want to test this more formally. This is actually very important because our estimates of variability (e.g., 95% CI) are sensitive to sample size, which varies by adults and children in this dataset.&lt;/p&gt;
&lt;div id=&#34;intra-correlation-coefficient-icc&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Intra-correlation coefficient (ICC)&lt;/h3&gt;
&lt;p&gt;The ICC is an index of reliability or agreement for continuous ratings. ICCs range from 0 (no agreement) to 1 (perfect agreement). We will use ICC to quantify agreement on ratings of emotional facial expressions, but ICC is applicable to other situations, such as quantifying heritability or assessing items in a test bank. Here, we will calculate four ICCs: (1) Adult ratings of Valence, (2) Child ratings of Valence, (3) Adults ratings of Arousal, and (4) Child ratings of Arousal.&lt;/p&gt;
&lt;p&gt;Shrout and Fleiss (1979), and later McGraw and Wong (1996), describe several different calculations for ICC that depend on the characteristics of the sample. In our case, we will use a two-way random model for single measurements to quantify absolute agreement, also known as ICC2.&lt;/p&gt;
&lt;p&gt;Two way random, single measures, absolute (ICC2):&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\rho = \frac{\sigma^2_r}{\sigma^2_r + \sigma^2_c + \sigma^2_e}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Where &lt;span class=&#34;math inline&#34;&gt;\(\rho\)&lt;/span&gt; is the population parameter for the ICC, &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2_r\)&lt;/span&gt; is the row variability (variability between raters), &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2_c\)&lt;/span&gt; is the column variability (variability between faces), and &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2_e\)&lt;/span&gt; is the error.&lt;/p&gt;
&lt;p&gt;We’re using a two way random model because we expect variability between subjects, but also within (faces have different underlying valence and arousal). Also note that the ‘single measures’ part is referring to the fact that each rating is a single score, not an average of scores.&lt;/p&gt;
&lt;p&gt;We’ll use the &lt;em&gt;ICC&lt;/em&gt; function from the &lt;em&gt;psych&lt;/em&gt; package to compute the ICCs.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(psych)

VA_adult_icc &amp;lt;- VA_adult %&amp;gt;%
  select(-face) %&amp;gt;%
  ICC()&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;VA_child_icc &amp;lt;- VA_child %&amp;gt;%
  select(-face) %&amp;gt;%
  ICC()&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;AR_adult_icc &amp;lt;- AR_adult %&amp;gt;%
  select(-face) %&amp;gt;%
  ICC()&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;AR_child_icc &amp;lt;- AR_child %&amp;gt;%
  select(-face) %&amp;gt;%
  ICC()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, we’ll use the &lt;em&gt;kableExtra&lt;/em&gt; package to generate a table of the results. Note that I’m extracting the 2nd value for the ICC results because it is the ICC2. If we expected no column variability then we might use ICC1.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(kableExtra)

kable(data.frame(matrix(c(VA_adult_icc$results$ICC[2], VA_child_icc$results$ICC[2],
                          AR_adult_icc$results$ICC[2], AR_child_icc$results$ICC[2]),
                   nrow = 2, ncol = 2),
                   row.names = c(&amp;quot;Adult&amp;quot;, &amp;quot;Child&amp;quot;)),
      col.names = c(&amp;quot;ICC Valence&amp;quot;, &amp;quot;ICC Arousal&amp;quot;)) %&amp;gt;%
  kable_styling()&lt;/code&gt;&lt;/pre&gt;
&lt;table class=&#34;table&#34; style=&#34;margin-left: auto; margin-right: auto;&#34;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
ICC Valence
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
ICC Arousal
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Adult
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.806
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.194
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Child
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.795
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.220
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Clearly and not surprisingly, the ICCs for arousal (~.20) are much lower than those for valence (~.80). Using Cicchetti’s (1994) guidelines, we would interpret the valence ICCs as indicating excellent agreement and the arousal ICCs as poor agreement. It is also worth noting that adults and children seem equally (un)reliable in their reporting.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;conclusions&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Conclusions&lt;/h2&gt;
&lt;p&gt;The findings suggest that we should give pause before attempting to interpret differences between children and adults in their overall ratings of arousal in facial expressions. Such disagreement is actually expected according to dimensional theories of emotion (Russell, 2003) because emotions are not viewed as prototypical things, and there can be wide variability in facial expressions even across similar situations. In other words, there’s no universal facial expression for high arousal (in fact, there’s little reason to believe in universality for any emotional expression).&lt;/p&gt;
&lt;div id=&#34;references&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;References&lt;/h3&gt;
&lt;p&gt;Cicchetti, D. V. (1994). Guidelines, criteria, and rules of thumb for evaluating normed and standardized assessment instruments in psychology. &lt;em&gt;Psychological Assessment, 6&lt;/em&gt;, 284-290.&lt;/p&gt;
&lt;p&gt;McGraw, K. O., &amp;amp; Wong, S. P. (1996). Forming inferences about some intraclass correlation coefficients. &lt;em&gt;Psychological Methods, 1&lt;/em&gt;, 30-46.&lt;/p&gt;
&lt;p&gt;Russell, J. A. (2003). Core affect and the psychological construction of emotion. &lt;em&gt;Psychological Review, 110&lt;/em&gt;, 145-172.&lt;/p&gt;
&lt;p&gt;Shrout, P. E., &amp;amp; Fleiss, J. L. (1979). Intraclass correlations: Uses in assessing reliability. &lt;em&gt;Psychological Bulletin, 86&lt;/em&gt;, 420-428.&lt;/p&gt;
&lt;p&gt;Vesker, M., Bahn, D., Dege, F., Kauschke, C., &amp;amp; Gudrun, S. (2018). Perceiving arousal and valence in facial expressions: Differences between children and adults. &lt;em&gt;European Journal of Developmental Psychology, 15&lt;/em&gt;, 411-425.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
      
            <category>R</category>
      
            <category>Emotion Dynamics</category>
      
      
            <category>R</category>
      
            <category>Emotion Dynamics</category>
      
    </item>
    
    <item>
      <title>Plotting the Affect Circumplex in R</title>
      <link>/post/circumplex/circumplex/</link>
      <pubDate>Tue, 15 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/circumplex/circumplex/</guid>
      <description>


&lt;p&gt;I’m a strong adherent to the &lt;em&gt;circumplex&lt;/em&gt; model of emotions introduced by James Russell in the late 1980s. Russell argued that all emotional experience can be boiled down to two dimensions: valence and arousal, with valence being how positive or negative you feel and arousal being how sluggish or emotionally activated you feel. The emotions we commonly label as anger, sadness, joy, etc. can be mapped within this &lt;em&gt;affective&lt;/em&gt; two-dimensional space, such that joy is a high valence, high arousal emotion, whereas boredom is a moderately low valence and low arousal emotion.&lt;/p&gt;
&lt;p&gt;This kind of model is great in the field of emotion dynamics, where we are interested in how emotions change over time. It’s great because we don’t have to get bogged down in philosophical debates about whether someone is in a state of sadness or not, but can instead focus on quantifying and mapping changes in valence and arousal. For my doctoral dissertation, I’m using the circumplex model of emotions to explore how emotions change over time in instances when people are alone or with others. Briefly, I’m interested in whether being alone reduces arousal (i.e., makes you more calm). Some evidence in support of this is offered in a recent paper by Nguyen, Ryan, &amp;amp; Deci (2018), although they didn’t use a circumplex approach to emotions.&lt;/p&gt;
&lt;p&gt;The circumplex model shines in another way: because it models emotional states in two dimensions, it can be presented visually. This is what I’m attempting to do for my own research. So for now, I’ll simulate some data akin to what I’ll be analyzing in my dissertation, starting simply with just two time points and one condition. The data will represent participants’ valence and arousal (Likert scale of 1-7) at baseline and the same measurements one hour later. I’ll use the &lt;em&gt;simstudy&lt;/em&gt; package to generate the data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(simstudy)
library(tidyverse)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here’s the code for simulating the data and binding it all together. I’m using the function &lt;em&gt;genCorGen&lt;/em&gt; to simulate and generate correlated data for valence and arousal, respectively. In this call, the params refer to the mean and standard deviations, while rho is the correlation coefficient.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(190113)

dx &amp;lt;- genCorGen(600, nvars = 2, params1 = c(4.79, 4.02), params2 = c(1.3, .9), dist = &amp;quot;normal&amp;quot;,
                rho = .67, corstr = &amp;quot;cs&amp;quot;, wide = TRUE,
                cnames = c(&amp;quot;valence1&amp;quot;, &amp;quot;valence2&amp;quot;))

dv &amp;lt;- genCorGen(600, nvars = 2, params1 = c(4.12, 3.97), params2 = c(.80, 1.2), dist = &amp;quot;normal&amp;quot;,
                rho = .43, corstr = &amp;quot;cs&amp;quot;, wide = TRUE,
                cnames = c(&amp;quot;arousal1&amp;quot;, &amp;quot;arousal2&amp;quot;))

core &amp;lt;- data.frame(round(dx), round(dv[, c(2, 3)]))

core$valence1[core$valence1 &amp;gt; 7] &amp;lt;- 7&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;After generating the data for valence and arousal, I binded the two variables, rounded them to the nearest integer, and trimmed cases that exceeded the 7-point cut-off.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(psych)

describe(core)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##          vars   n   mean     sd median trimmed    mad min max range  skew
## id          1 600 300.50 173.35  300.5  300.50 222.39   1 600   599  0.00
## valence1    2 600   4.81   1.10    5.0    4.84   1.48   1   7     6 -0.16
## valence2    3 600   4.06   0.94    4.0    4.05   1.48   1   7     6 -0.01
## arousal1    4 600   4.14   0.92    4.0    4.15   1.48   2   7     5 -0.10
## arousal2    5 600   4.08   1.14    4.0    4.09   1.48   1   7     6 -0.05
##          kurtosis   se
## id          -1.21 7.08
## valence1    -0.12 0.04
## valence2     0.17 0.04
## arousal1    -0.26 0.04
## arousal2    -0.05 0.05&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The summary statistics check out. So now it’s time to plot the data. The function I’m quaintly calling &lt;em&gt;circumplexi&lt;/em&gt; takes four vectors as inputs (time 1 valence, time 2 valence, time 1 arousal, time 2 arousal) and returns a circumplex plot. As it stands, it’s not the most intuitive function, but it produces a decent looking plot.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;circumplexi &amp;lt;- function(valence_time1, valence_time2, arousal_time1, arousal_time2) {
  v1 &amp;lt;- valence_time1
  v2 &amp;lt;- valence_time2
  a1 &amp;lt;- arousal_time1
  a2 &amp;lt;- arousal_time2
  
  v1mean &amp;lt;- mean(valence_time1, na.rm = TRUE)
  v2mean &amp;lt;- mean(valence_time2, na.rm = TRUE)
  a1mean &amp;lt;- mean(arousal_time1, na.rm = TRUE)
  a2mean &amp;lt;- mean(arousal_time2, na.rm = TRUE)
  
  ggplot() +
    geom_segment(aes(x = (min(v1) + max(v1))/2, y = min(v1), xend = (min(v1) + max(v1))/2, yend = max(v1)), color = &amp;quot;gray60&amp;quot;, size = 1) +
    geom_segment(aes(x = min(v1), y = (min(v1) + max(v1))/2, xend = max(v1), yend = (min(v1) + max(v1))/2), color = &amp;quot;gray60&amp;quot;, size = 1) +
    geom_point(aes(x = a1mean, y = v1mean, size = 5, color = &amp;quot;Time 1&amp;quot;)) +
    geom_point(aes(x = a2mean, y = v2mean, size = 5, color = &amp;quot;Time 2&amp;quot;)) +
    scale_x_discrete(name = &amp;quot;arousal&amp;quot;, limits = c(min(v1):max(v1)), expand = c(0, 0)) +
    scale_y_discrete(name = &amp;quot;valence&amp;quot;, limits = c(min(v1):max(v1)), expand = c(0, 0)) +
    geom_segment(aes(x = a1mean,
                     y = v1mean, 
                     xend = a2mean,
                     yend = v2mean),
                 arrow = arrow(type = &amp;quot;closed&amp;quot;, length = unit(.125, &amp;quot;inches&amp;quot;))) +
    coord_fixed() + 
    theme_light() +
    labs(title = &amp;quot;Change in Affect from Time 1 to Time 2&amp;quot;,
         subtitle = &amp;quot;Red dot is affect at Time 1. Blue dot is affect at Time 2&amp;quot;) +
    theme(legend.position = &amp;quot;none&amp;quot;)
}&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;circumplexi(core$valence1, core$valence2, core$arousal1, core$arousal2)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/circumplex/Affect_Circumplex_files/figure-html/unnamed-chunk-5-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;In this example, the plot shows that affect becomes more neutral (i.e, returns to baseline) following Time 1. In my own research, I’ll be using circumplex plots to depict this change between multiple groups as well. For now, this is a good start.&lt;/p&gt;
</description>
      
            <category>R</category>
      
            <category>Emotion Dynamics</category>
      
      
            <category>R</category>
      
            <category>Emotion Dynamics</category>
      
    </item>
    
  </channel>
</rss>
