<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Bayesian on Will Hipson</title>
    <link>/tags/bayesian/</link>
    <description>Recent content in Bayesian on Will Hipson</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2020</copyright>
    <lastBuildDate>Tue, 28 Jan 2020 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/tags/bayesian/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>An Intuitive Look at Binomial Probability in a Bayesian Context</title>
      <link>/post/bayesian_intro/binomial_gold/</link>
      <pubDate>Tue, 28 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>/post/bayesian_intro/binomial_gold/</guid>
      <description>Binomial probability is the relatively simple case of estimating the proportion of successes in a series of yes/no trials. The perennial example is estimating the proportion of heads in a series of coin flips where each trial is independent and has possibility of heads or tails. Because of its relative simplicity, the binomial case is a great place to start when learning about Bayesian analysis. In this post, I will provide a gentle introduction to Bayesian analysis using binomial probability as an example.</description>
    </item>
    
    <item>
      <title>Bayesian Linear Mixed Models: Random Intercepts, Slopes, and Missing Data</title>
      <link>/post/bayesian_mlm/bayesian_mlm/</link>
      <pubDate>Thu, 05 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/bayesian_mlm/bayesian_mlm/</guid>
      <description>This past summer, I watched a brilliant lecture series by Richard McElreath on Bayesian statistics. It honestly changed my whole outlook on statistics, so I couldn’t recommend it more (plus, McElreath is an engaging instructor). One of the most compelling cases for using Bayesian statistics is with a collection of statistical tools called linear mixed models or multilevel/hierarchical models. It’s common that data are grouped or clustered in some way.</description>
    </item>
    
  </channel>
</rss>